# PromptProof

A powerful testing framework for evaluating Large Language Models (LLMs) with a modular evaluation system and real-time dashboard.

## Features

- ðŸ§ª Jest-like syntax for writing LLM tests
- ðŸ“Š Real-time test execution dashboard
- ðŸ”„ Multiple evaluation strategies:
  - Semantic Similarity (embeddings, BLEU, ROUGE)
  - LLM-based evaluation
  - Rule-based validation
  - Custom evaluators
- ðŸ”— Chain evaluators with weights
- ðŸŽ¯ Configurable thresholds and parameters
- ðŸš€ Support for multiple LLM providers (Anthropic, OpenAI)
- ðŸ“ˆ Detailed test reports and analysis

## Installation
