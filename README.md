# LLM Test Runner

A testing framework for evaluating Large Language Models (LLMs) with a Jest-like syntax and a real-time dashboard.

## Features

- Jest-like syntax for writing LLM tests
- Real-time test execution dashboard
- Support for multiple LLM providers (Anthropic, OpenAI)
- Multiple evaluation metrics (BLEU, ROUGE, Semantic Similarity)
- LLM-based evaluation and feedback
- Real-time test results with WebSocket
- Configurable model parameters and thresholds

## Installation
